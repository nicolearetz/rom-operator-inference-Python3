{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87df386",
   "metadata": {},
   "source": [
    "# Nested Operator Inference\n",
    "\n",
    "**TODO:** Add description\n",
    "**TODO:** Why consider nested OpInf?\n",
    "- start from smaller space\n",
    "- way to update ROM\n",
    "\n",
    "[1] Aretz, Nicole, and Karen Willcox. \"Enforcing structure in data-driven reduced modeling through nested Operator Inference.\" In 2024 IEEE 63rd Conference on Decision and Control (CDC), pp. 8046-8053. IEEE, 2024.\n",
    "\n",
    "[2] Aretz, Nicole, and Karen Willcox. \"Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models.\" arXiv preprint arXiv:2508.11542 (2025).\n",
    "\n",
    "[3] Qian, Elizabeth, Ionut-Gabriel Farcas, and Karen Willcox. \"Reduced operator inference for nonlinear partial differential equations.\" SIAM Journal on Scientific Computing 44, no. 4 (2022): A1934-A1959.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18385c38",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "We consider the cubic example from [2], section 5.1: For a heat conduction parameter $\\kappa \\in [0.001, 0.1]$, identiy $x(t,z)$ with\n",
    "$$\\dot{x}(t, z) = \\kappa \\Delta_z x(t, z) - x(t, z)^3, \\qquad \\forall t > 0, z \\in (0, 1)$$\n",
    "with initial condition $x(0, z) = 10z(1-z)$ and zero-Dirichlet boundary conditions $x(t, 0) = x(t, 1) = 0$ for all $t>0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ea9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import opinf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c7a51",
   "metadata": {},
   "source": [
    "## Full-order model data\n",
    "The problem is discretized using linear finite elements, and solved with Crank-Nicholson time-stepping using a step size of $\\Delta t = 0.001$. \n",
    "\n",
    "The training and testing data used in [2] can be downloaded here. After the download, change the `path_to_data` variable below to where the data was saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab8afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"/storage/nicole/git-save-data/opinf/cubic-heat/paper/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45b22ec",
   "metadata": {},
   "source": [
    "We load the whole data set for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3464de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in training and testing data\n",
    "with open(path_to_data + \"trainingdata\", \"rb\") as file:\n",
    "    Xi_test, U_para_test, compute_time = pickle.load(file)\n",
    "\n",
    "nFE = U_para_test[0].shape[0] # finite element dimension\n",
    "grid_t = np.arange(0, 1+0.001, 0.001) # temporal discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f918697",
   "metadata": {},
   "source": [
    "The parameter $\\kappa$ does SOMETHING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca705644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: figure for how the parameter changes the FOM solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec702a5",
   "metadata": {},
   "source": [
    "For training, we only use the data from three parameters: $\\kappa = 0.001$, $\\kappa = 0.01$, $\\kappa = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8116e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameters: [0.001 0.01  0.1  ]\n"
     ]
    }
   ],
   "source": [
    "# specify what we use as training data\n",
    "final_training_time = 0.2\n",
    "indices_training_parameters = [0, 100, 200]\n",
    "\n",
    "# extract training data\n",
    "K_train = np.argmin(np.abs(grid_t - final_training_time)) + 1\n",
    "n_para = len(indices_training_parameters)\n",
    "Xi_train = Xi_test[indices_training_parameters, :] # training parameters\n",
    "U_para = U_para_test[indices_training_parameters] # training snapshots\n",
    "print(\"Training parameters:\", Xi_train[:, 0])\n",
    "\n",
    "# only use data up to end of training time\n",
    "for i in range(n_para):\n",
    "    U_para[i] = U_para[i][:, :K_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee2c9c",
   "metadata": {},
   "source": [
    "We build a reduced space using the training data. First, we scale the data. We do not center it because that would introduce constant and quadratic terms for additional degrees of freedom we would need to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8806b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned maxnorm scaling Q -> Q''\n",
      "    |     min    |    mean    |     max    |    std\n",
      "----|------------|------------|------------|------------\n",
      "Q   |  0.000e+00 |  1.235e+00 |  2.500e+00 |  5.424e-01\n",
      "Q'' |  0.000e+00 |  2.139e-02 |  4.330e-02 |  9.395e-03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stack the training data next to each other, the transformer doesn't know about the parameterization\n",
    "U_stacked = np.hstack(U_para)\n",
    "\n",
    "# initialize the transformer\n",
    "transformer = opinf.pre.ShiftScaleTransformer(centering = False, scaling = 'maxnorm', verbose = True)\n",
    "U_transformed = transformer.fit_transform(U_stacked)\n",
    "\n",
    "# apply the transformation individually to the data for each parameter\n",
    "U_train = [transformer.transform(u) for u in U_para]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddad1f3",
   "metadata": {},
   "source": [
    "Second, we compute the singular value decay of the transformed data. We use the method of snapshots with the mass of the finite element discretization as inner product matrix. Doing so follows the analysis in [3] about Operator Inference for partial differential equations. When the mass matrix is not available, we can use the identity matrix instead as an approximation. Because the problem is already discretized, the Euclidean norm of the finite element coefficients is equivalent to the $L^2((0,1))$ norm of their encoded function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb9709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment in next part to treat mass matrix as unknown\n",
    "from scipy.sparse import eye\n",
    "mass_matrix = eye(nFE)\n",
    "\n",
    "VR, svdvals, __ = opinf.basis.method_of_snapshots(states=U_transformed, inner_product_matrix=mass_matrix, minthresh=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ec434b",
   "metadata": {},
   "source": [
    "Third, we look at the singular value decay to choose the reduced dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03a2873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: use package to choose reduced dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311ffb1",
   "metadata": {},
   "source": [
    "## Operator Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796d9d1",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a34fbd",
   "metadata": {},
   "source": [
    "### Classic Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b389a",
   "metadata": {},
   "source": [
    "### Nested Operator Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67427f56",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb4c56",
   "metadata": {},
   "source": [
    "## The End."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opinf-contributions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
